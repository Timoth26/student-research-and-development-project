{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8YzC6R9yNvI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "from tensorflow.keras import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGzdmoulyNvL"
      },
      "outputs": [],
      "source": [
        "# Path to the data directory\n",
        "data_dir = \"/content/handwriting-recognition/test_v2/test/\"\n",
        "train_csv = pd.read_csv('/content/handwriting-recognition//written_name_test_v2.csv')\n",
        "\n",
        "train_csv = train_csv[train_csv['IDENTITY'] != 'UNREADABLE']\n",
        "train_csv = train_csv[train_csv['IDENTITY'] != 'BLANK']\n",
        "train_csv = train_csv.sample(frac=0.05, random_state=42)\n",
        "print(train_csv.shape[0])\n",
        "\n",
        "images = list(train_csv['FILENAME'])\n",
        "labels = list(train_csv['IDENTITY'].astype(str))\n",
        "train_csv = train_csv.dropna(subset=['IDENTITY'])\n",
        "\n",
        "images = [os.path.join(data_dir, img) for img in images]\n",
        "\n",
        "characters = set(char for label in labels if isinstance(label, str) for char in label)\n",
        "characters = sorted(list(characters))\n",
        "\n",
        "print(\"Number of images found: \", len(images))\n",
        "print(\"Number of labels found: \", len(labels))\n",
        "print(\"Number of unique characters: \", len(characters))\n",
        "print(\"Characters present: \", characters)\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 16\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width = 200\n",
        "img_height = 40\n",
        "\n",
        "# Factor by which the image is going to be downsampled\n",
        "# by the convolutional blocks. We will be using two\n",
        "# convolution blocks and each block will have\n",
        "# a pooling layer which downsample the features by a factor of 2.\n",
        "# Hence total downsampling factor would be 4.\n",
        "downsample_factor = 4\n",
        "# Maximum length of any captcha in the dataset\n",
        "max_length = max([len(str(label)) for label in train_csv['IDENTITY']])\n",
        "print(max_length)\n",
        "labels = [label.ljust(max_length) for label in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU0-HEe4yNvN"
      },
      "outputs": [],
      "source": [
        "# Mapping characters to integers\n",
        "char_to_num = layers.StringLookup(vocabulary=list(characters), mask_token=None)\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "def split_data(images, labels, train_size=0.9, shuffle=True):\n",
        "    # 1. Get the total size of the dataset\n",
        "    size = len(images)\n",
        "    # 2. Make an indices array and shuffle it, if required\n",
        "    indices = ops.arange(size)\n",
        "    if shuffle:\n",
        "        keras.random.shuffle(indices)\n",
        "    # 3. Get the size of training samples\n",
        "    train_samples = int(size * train_size)\n",
        "    # 4. Split data into training and validation sets\n",
        "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
        "    x_test, y_test = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
        "    return x_train, x_valid, y_train, y_valid, x_test, y_test\n",
        "\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid, x_test, y_test = split_data(np.array(images), np.array(labels))\n",
        "\n",
        "\n",
        "def encode_single_sample(img_path, label):\n",
        "    # 1. Read image\n",
        "    img = tf.io.read_file(img_path)\n",
        "    # 2. Decode and convert to grayscale\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    # 3. Convert to float32 in [0, 1] range\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    # 4. Resize to the desired size\n",
        "    img = tf.image.resize(img, [img_height, img_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    # 5. Transpose the image because we want the time\n",
        "    # dimension to correspond to the width of the image.\n",
        "    img = ops.transpose(img, axes=[1, 0, 2])\n",
        "    # 6. Map the characters in label to numbers\n",
        "    print(label)\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "    # 7. Return a dict as our model is expecting two inputs\n",
        "    print(label)\n",
        "    return {\"image\": img, \"label\": label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b_JH_z1yNvO"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = (\n",
        "    test_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9g64W-jyNvQ"
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots(4, 4, figsize=(10, 5))\n",
        "for batch in train_dataset.take(1):\n",
        "    print('a')\n",
        "    images = batch[\"image\"]\n",
        "    labels = batch[\"label\"]\n",
        "    for i in range(16):\n",
        "        img = (images[i] * 255).numpy().astype(\"uint8\")\n",
        "        label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8\")\n",
        "        ax[i // 4, i % 4].imshow(img[:, :, 0].T, cmap=\"gray\")\n",
        "        ax[i // 4, i % 4].set_title(label)\n",
        "        ax[i // 4, i % 4].axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq18FOqAyNvR"
      },
      "outputs": [],
      "source": [
        "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n",
        "    label_length = ops.cast(ops.squeeze(label_length, axis=-1), dtype=\"int32\")\n",
        "    input_length = ops.cast(ops.squeeze(input_length, axis=-1), dtype=\"int32\")\n",
        "    sparse_labels = ops.cast(\n",
        "        ctc_label_dense_to_sparse(y_true, label_length), dtype=\"int32\"\n",
        "    )\n",
        "\n",
        "    y_pred = ops.log(ops.transpose(y_pred, axes=[1, 0, 2]) + keras.backend.epsilon())\n",
        "\n",
        "    return ops.expand_dims(\n",
        "        tf.compat.v1.nn.ctc_loss(\n",
        "            inputs=y_pred, labels=sparse_labels, sequence_length=input_length\n",
        "        ),\n",
        "        1,\n",
        "    )\n",
        "\n",
        "\n",
        "def ctc_label_dense_to_sparse(labels, label_lengths):\n",
        "    label_shape = ops.shape(labels)\n",
        "    num_batches_tns = ops.stack([label_shape[0]])\n",
        "    max_num_labels_tns = ops.stack([label_shape[1]])\n",
        "\n",
        "    def range_less_than(old_input, current_input):\n",
        "        return ops.expand_dims(ops.arange(ops.shape(old_input)[1]), 0) < tf.fill(\n",
        "            max_num_labels_tns, current_input\n",
        "        )\n",
        "\n",
        "    init = ops.cast(tf.fill([1, label_shape[1]], 0), dtype=\"bool\")\n",
        "    dense_mask = tf.compat.v1.scan(\n",
        "        range_less_than, label_lengths, initializer=init, parallel_iterations=1\n",
        "    )\n",
        "    dense_mask = dense_mask[:, 0, :]\n",
        "\n",
        "    label_array = ops.reshape(\n",
        "        ops.tile(ops.arange(0, label_shape[1]), num_batches_tns), label_shape\n",
        "    )\n",
        "    label_ind = tf.compat.v1.boolean_mask(label_array, dense_mask)\n",
        "\n",
        "    batch_array = ops.transpose(\n",
        "        ops.reshape(\n",
        "            ops.tile(ops.arange(0, label_shape[0]), max_num_labels_tns),\n",
        "            tf.reverse(label_shape, [0]),\n",
        "        )\n",
        "    )\n",
        "    batch_ind = tf.compat.v1.boolean_mask(batch_array, dense_mask)\n",
        "    indices = ops.transpose(\n",
        "        ops.reshape(ops.concatenate([batch_ind, label_ind], axis=0), [2, -1])\n",
        "    )\n",
        "\n",
        "    vals_sparse = tf.compat.v1.gather_nd(labels, indices)\n",
        "\n",
        "    return tf.SparseTensor(\n",
        "        ops.cast(indices, dtype=\"int64\"),\n",
        "        vals_sparse,\n",
        "        ops.cast(label_shape, dtype=\"int64\")\n",
        "    )\n",
        "\n",
        "@keras.saving.register_keras_serializable(package=\"customs\", name=\"CTCLayer\")\n",
        "class CTCLayer(layers.Layer):\n",
        "    # def __init__(self, name=None):\n",
        "    #     super().__init__(name=name)\n",
        "    #     self.loss_fn = ctc_batch_cost\n",
        "    def __init__(self, trainable=True, dtype='float32', name=None, **kwargs):\n",
        "        super().__init__(trainable=trainable, dtype=dtype, name=name, **kwargs)\n",
        "        self.loss_fn = ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        batch_len = ops.cast(ops.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = ops.cast(ops.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = ops.cast(ops.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * ops.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * ops.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions\n",
        "        return y_pred\n",
        "\n",
        "def build_model(num_conv_layers=1, filter_size=3, activation='relu'):\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(\n",
        "        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
        "    )\n",
        "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
        "\n",
        "    # First conv block\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (filter_size, filter_size),\n",
        "        activation=activation,\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Usuń drugą warstwę konwolucyjną i odpowiadający jej blok pooleowania\n",
        "    # Druga warstwa konwolucyjna\n",
        "    # x = layers.Conv2D(\n",
        "    #     64,\n",
        "    #     (filter_size, filter_size),\n",
        "    #     activation=activation,\n",
        "    #     kernel_initializer=\"he_normal\",\n",
        "    #     padding=\"same\",\n",
        "    #     name=\"Conv2\",\n",
        "    # )(x)\n",
        "    # x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    # We have used one max pool with pool size and strides 2.\n",
        "    # Hence, downsampled feature maps are 2x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing the output to the RNN part of the model\n",
        "    new_shape = ((img_width // 2), (img_height // 2) * 64)  # Zmiana rozmiaru tensora po usunięciu drugiej warstwy konwolucyjnej\n",
        "    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.Dense(\n",
        "        len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\"\n",
        "    )(x)\n",
        "\n",
        "    # Add CTC layer for calculating CTC loss at each step\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n",
        "    )\n",
        "    # Optimizer\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return\n",
        "    model.compile(optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = build_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_ypsNZByNvS"
      },
      "outputs": [],
      "source": [
        "def character_error_rate(y_true, y_pred):\n",
        "    # Convert integer labels back to strings\n",
        "    y_true = tf.strings.reduce_join(num_to_char(y_true), axis=-1)\n",
        "    y_pred = tf.strings.reduce_join(num_to_char(y_pred), axis=-1)\n",
        "\n",
        "    # Compute Levenshtein distance between true and predicted strings\n",
        "    distances = tf.edit_distance(y_true, y_pred, normalize=False)\n",
        "\n",
        "    # Compute total number of characters in true labels\n",
        "    total_characters = tf.strings.length(y_true)\n",
        "\n",
        "    # Calculate CER as the average distance normalized by total number of characters\n",
        "    cer = tf.reduce_mean(distances / total_characters)\n",
        "\n",
        "    return cer\n",
        "\n",
        "def word_error_rate(y_true, y_pred):\n",
        "    # Convert integer labels back to strings\n",
        "    y_true = tf.strings.reduce_join(num_to_char(y_true), axis=-1)\n",
        "    y_pred = tf.strings.reduce_join(num_to_char(y_pred), axis=-1)\n",
        "\n",
        "    # Split true and predicted strings into words\n",
        "    true_words = tf.strings.split(y_true)\n",
        "    pred_words = tf.strings.split(y_pred)\n",
        "\n",
        "    # Compute Levenshtein distance between true and predicted words\n",
        "    distances = tf.edit_distance(true_words, pred_words, normalize=False)\n",
        "\n",
        "    # Compute total number of words in true labels\n",
        "    total_words = tf.cast(tf.size(true_words), tf.float32)\n",
        "\n",
        "    # Calculate WER as the average distance normalized by total number of words\n",
        "    wer = tf.reduce_mean(distances / total_words)\n",
        "\n",
        "    return wer\n",
        "\n",
        "def token_error_rate(y_true, y_pred):\n",
        "    # Convert integer labels back to strings\n",
        "    y_true = tf.strings.reduce_join(num_to_char(y_true), axis=-1)\n",
        "    y_pred = tf.strings.reduce_join(num_to_char(y_pred), axis=-1)\n",
        "\n",
        "    # Tokenize true and predicted strings\n",
        "    true_tokens = tf.strings.regex_replace(y_true, r\"([.,!?;])\", r\" \\1 \")  # Add space around punctuation\n",
        "    true_tokens = tf.strings.split(true_tokens)\n",
        "    pred_tokens = tf.strings.regex_replace(y_pred, r\"([.,!?;])\", r\" \\1 \")  # Add space around punctuation\n",
        "    pred_tokens = tf.strings.split(pred_tokens)\n",
        "\n",
        "    # Compute Levenshtein distance between true and predicted tokens\n",
        "    distances = tf.edit_distance(true_tokens, pred_tokens, normalize=False)\n",
        "\n",
        "    # Compute total number of tokens in true labels\n",
        "    total_tokens = tf.cast(tf.size(true_tokens), tf.float32)\n",
        "\n",
        "    # Calculate TER as the average distance normalized by total number of tokens\n",
        "    ter = tf.reduce_mean(distances / total_tokens)\n",
        "\n",
        "    return ter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0toHqT01yNvS",
        "outputId": "5573683c-a865-4a50-ff59-edbdc17d73b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 476ms/step - loss: 727.7364 - val_loss: 418.9305\n",
            "Epoch 2/5\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 476ms/step - loss: 402.5636 - val_loss: 409.3893\n",
            "Epoch 3/5\n",
            "\u001b[1m 57/117\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 416ms/step - loss: 395.4935"
          ]
        }
      ],
      "source": [
        "# TODO restore epoch count.\n",
        "epochs = 5\n",
        "early_stopping_patience = 10\n",
        "# Add early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrCNMnWOyNvT"
      },
      "outputs": [],
      "source": [
        "model.save(\"trained_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EELHx90qyNvU"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_dataset)\n",
        "\n",
        "# def decode_predictions(predictions):\n",
        "#     decoded_predictions = []\n",
        "#     for prediction in predictions:\n",
        "#         # Numery do znaków\n",
        "#         decoded_labels = num_to_char(prediction)\n",
        "#         # Połączenie znaków w string\n",
        "#         decoded_string = tf.strings.reduce_join(decoded_labels, axis=-1)\n",
        "#         # Dodanie zdekodowanej etykiety do listy\n",
        "#         decoded_predictions.append(decoded_string)\n",
        "#     return decoded_predictions\n",
        "\n",
        "# # Dekodowanie przewidywań\n",
        "# decoded_predictions = decode_predictions(predictions)\n",
        "# print(decoded_predictions)\n",
        "\n",
        "# Mapping characters to integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVtZbHiJyNvV"
      },
      "outputs": [],
      "source": [
        "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n",
        "    input_shape = ops.shape(y_pred)\n",
        "    num_samples, num_steps = input_shape[0], input_shape[1]\n",
        "    y_pred = ops.log(ops.transpose(y_pred, axes=[1, 0, 2]) + keras.backend.epsilon())\n",
        "    input_length = ops.cast(input_length, dtype=\"int32\")\n",
        "\n",
        "    if greedy:\n",
        "        (decoded, log_prob) = tf.nn.ctc_greedy_decoder(\n",
        "            inputs=y_pred, sequence_length=input_length\n",
        "        )\n",
        "    else:\n",
        "        (decoded, log_prob) = tf.compat.v1.nn.ctc_beam_search_decoder(\n",
        "            inputs=y_pred,\n",
        "            sequence_length=input_length,\n",
        "            beam_width=beam_width,\n",
        "            top_paths=top_paths,\n",
        "        )\n",
        "    decoded_dense = []\n",
        "    for st in decoded:\n",
        "        st = tf.SparseTensor(st.indices, st.values, (num_samples, num_steps))\n",
        "        decoded_dense.append(tf.sparse.to_dense(sp_input=st, default_value=-1))\n",
        "    return (decoded_dense, log_prob)\n",
        "\n",
        "\n",
        "# Get the prediction model by extracting layers till the output layer\n",
        "prediction_model = keras.models.Model(\n",
        "    model.input[0], model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "prediction_model.summary()\n",
        "\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "#  Let's check results on some validation samples\n",
        "for batch in validation_dataset.take(1):\n",
        "    batch_images = batch[\"image\"]\n",
        "    batch_labels = batch[\"label\"]\n",
        "\n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    _, ax = plt.subplots(4, 4, figsize=(15, 5))\n",
        "    for i in range(len(pred_texts)):\n",
        "        img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n",
        "        img = img.T\n",
        "        title = f\"Prediction: {pred_texts[i]}\\nReal: {orig_texts[i]}\"\n",
        "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
        "        ax[i // 4, i % 4].set_title(title)\n",
        "        ax[i // 4, i % 4].axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVQz5JJqyNvX"
      },
      "outputs": [],
      "source": [
        "def levenshtein(s1, s2):\n",
        "    dp = [[0] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n",
        "\n",
        "    for i in range(len(s1) + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(len(s2) + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, len(s1) + 1):\n",
        "        for j in range(1, len(s2) + 1):\n",
        "            if s1[i - 1] == s2[j - 1]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = 1\n",
        "            dp[i][j] = min(dp[i - 1][j] + 1,\n",
        "                           dp[i][j - 1] + 1,\n",
        "                           dp[i - 1][j - 1] + cost)\n",
        "    return dp[len(s1)][len(s2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZDW6EpXyNvY"
      },
      "outputs": [],
      "source": [
        "total_distance = 0\n",
        "num_samples = 0\n",
        "for batch in validation_dataset:\n",
        "    batch_images = batch[\"image\"]\n",
        "    batch_labels = batch[\"label\"]\n",
        "\n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    for i in range(len(pred_texts)):\n",
        "        total_distance += levenshtein(pred_texts[i], orig_texts[i])\n",
        "        num_samples += 1\n",
        "\n",
        "\n",
        "# Calculate and print the average Levenshtein distance\n",
        "average_distance = total_distance / num_samples\n",
        "print(f\"Average Levenshtein Distance: {average_distance}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}