{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "import scipy.stats as stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_full(scaller,normalization,filter_size,activation):\n",
    "    \"\"\"\n",
    "    Builds and trains a handwritten text recognition model using Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).\n",
    "\n",
    "    Args:\n",
    "    - scaller (float): Scaling factor for image dimensions.\n",
    "    - normalization (str): Type of image normalization. Supported options are 'zscore' and 'minmax'.\n",
    "    - filter_size (int): Size of the convolutional filters.\n",
    "    - activation (str): Activation function used in the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average Levenshtein Distance between predicted and true labels.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = \"/content/handwriting-recognition/test_v2/test/\"\n",
    "    train_csv = pd.read_csv('/content/handwriting-recognition/written_name_test_v2.csv')\n",
    "\n",
    "    train_csv = train_csv[train_csv['IDENTITY'] != 'UNREADABLE']\n",
    "    train_csv = train_csv[train_csv['IDENTITY'] != 'BLANK']\n",
    "    train_csv = train_csv.sample(frac=0.001, random_state=42)\n",
    "\n",
    "    images = list(train_csv['FILENAME'])\n",
    "    labels = list(train_csv['IDENTITY'].astype(str))\n",
    "    train_csv = train_csv.dropna(subset=['IDENTITY'])\n",
    "\n",
    "    images = [os.path.join(data_dir, img) for img in images]\n",
    "\n",
    "    characters = set(char for label in labels if isinstance(label, str) for char in label)\n",
    "    characters = sorted(list(characters))\n",
    "\n",
    "    batch_size = 16\n",
    "    img_width = 200\n",
    "    img_height = 40\n",
    "    downsample_factor = 4\n",
    "    max_length = max([len(str(label)) for label in train_csv['IDENTITY']])\n",
    "    labels = [label.ljust(max_length) for label in labels]\n",
    "\n",
    "    scaller = scaller\n",
    "    normalization = normalization\n",
    "    filter_size = filter_size\n",
    "    activation = activation\n",
    "\n",
    "    def scale_image(scaller):\n",
    "        \"\"\"\n",
    "        Scales the image dimensions based on the provided scaling factor.\n",
    "\n",
    "        Args:\n",
    "        - scaller (float): Scaling factor for image dimensions.\n",
    "        \"\"\"\n",
    "        img_width = int(200 * scaller)\n",
    "        img_height = int(40 * scaller)\n",
    "\n",
    "    char_to_num = layers.StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "    num_to_char = layers.StringLookup(\n",
    "        vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    "    )\n",
    "\n",
    "    def split_data(images, labels, train_size=0.8, valid_size=0.1, test_size=0.1, shuffle=True, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the dataset into training, validation, and test sets.\n",
    "\n",
    "        Args:\n",
    "        - images (list): List of image file paths.\n",
    "        - labels (list): List of corresponding labels.\n",
    "        - train_size (float): Proportion of data to include in the training set.\n",
    "        - valid_size (float): Proportion of data to include in the validation set.\n",
    "        - test_size (float): Proportion of data to include in the test set.\n",
    "        - shuffle (bool): Whether to shuffle the data before splitting.\n",
    "        - random_state (int): Seed for random number generation.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: Splits of training, validation, and test datasets.\n",
    "        \"\"\"\n",
    "        size = len(images)\n",
    "        if shuffle:\n",
    "            rng = np.random.default_rng(random_state)\n",
    "            indices = rng.permutation(size)\n",
    "        else:\n",
    "            indices = np.arange(size)\n",
    "        train_samples = int(size * train_size)\n",
    "        valid_samples = int(size * valid_size)\n",
    "        test_samples = int(size * test_size)\n",
    "        x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
    "        x_valid, y_valid = images[indices[train_samples:train_samples + valid_samples]], labels[indices[train_samples:train_samples + valid_samples]]\n",
    "        x_test, y_test = images[indices[train_samples:train_samples + test_samples:]], labels[indices[train_samples:train_samples + test_samples:]]\n",
    "        return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(np.array(images), np.array(labels))\n",
    "\n",
    "    def encode_single_sample(img_path, label, scaller, normalization):\n",
    "        \"\"\"\n",
    "        Encodes a single image-label pair for training the model.\n",
    "\n",
    "        Args:\n",
    "        - img_path (str): File path of the image.\n",
    "        - label (str): Label corresponding to the image.\n",
    "        - scaller (float): Scaling factor for image dimensions.\n",
    "        - normalization (str): Type of image normalization.\n",
    "\n",
    "        Returns:\n",
    "        - dict: Dictionary containing the encoded image and label.\n",
    "        \"\"\"\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.io.decode_png(img, channels=1)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        scale_image(scaller)\n",
    "        img = tf.image.resize(img, [img_height, img_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        img = ops.transpose(img, axes=[1, 0, 2])\n",
    "        if normalization == \"zscore\":\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "        elif normalization == \"minmax\":\n",
    "            img = (img - tf.reduce_min(img)) / (tf.reduce_max(img) - tf.reduce_min(img))\n",
    "        label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = (\n",
    "        train_dataset.map(lambda x, y: encode_single_sample(x, y, scaller, normalization), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "    validation_dataset = (\n",
    "        validation_dataset.map(lambda x, y: encode_single_sample(x, y, scaller, normalization), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = (\n",
    "        test_dataset.map(lambda x, y: encode_single_sample(x, y, scaller, normalization), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    _, ax = plt.subplots(4, 4, figsize=(10, 5))\n",
    "    for batch in train_dataset.take(1):\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "        for i in range(16):\n",
    "            img = (images[i] * 255).numpy().astype(\"uint8\")\n",
    "            label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8\")\n",
    "            ax[i // 4, i % 4].imshow(img[:, :, 0].T, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(label)\n",
    "            ax[i // 4, i % 4].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n",
    "        \"\"\"\n",
    "        Computes the Connectionist Temporal Classification (CTC) loss for a batch of predictions.\n",
    "\n",
    "        Args:\n",
    "        - y_true (tensor): True labels.\n",
    "        - y_pred (tensor): Predicted labels.\n",
    "        - input_length (tensor): Length of the input sequence.\n",
    "        - label_length (tensor): Length of the true labels.\n",
    "\n",
    "        Returns:\n",
    "        - tensor: Batch-wise CTC loss.\n",
    "        \"\"\"\n",
    "        label_length = ops.cast(ops.squeeze(label_length, axis=-1), dtype=\"int32\")\n",
    "        input_length = ops.cast(ops.squeeze(input_length, axis=-1), dtype=\"int32\")\n",
    "        sparse_labels = ops.cast(\n",
    "            ctc_label_dense_to_sparse(y_true, label_length), dtype=\"int32\"\n",
    "        )\n",
    "\n",
    "        y_pred = ops.log(ops.transpose(y_pred, axes=[1, 0, 2]) + keras.backend.epsilon())\n",
    "\n",
    "        return ops.expand_dims(\n",
    "            tf.compat.v1.nn.ctc_loss(\n",
    "                inputs=y_pred, labels=sparse_labels, sequence_length=input_length\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def ctc_label_dense_to_sparse(labels, label_lengths):\n",
    "        \"\"\"\n",
    "        Converts dense labels to sparse representation for CTC loss calculation.\n",
    "\n",
    "        Args:\n",
    "        - labels (tensor): Dense representation of labels.\n",
    "        - label_lengths (tensor): Length of each label.\n",
    "\n",
    "        Returns:\n",
    "        - SparseTensor: Sparse representation of labels.\n",
    "        \"\"\"\n",
    "        label_shape = ops.shape(labels)\n",
    "        num_batches_tns = ops.stack([label_shape[0]])\n",
    "        max_num_labels_tns = ops.stack([label_shape[1]])\n",
    "\n",
    "        def range_less_than(old_input, current_input):\n",
    "            return ops.expand_dims(ops.arange(ops.shape(old_input)[1]), 0) < tf.fill(\n",
    "                max_num_labels_tns, current_input\n",
    "            )\n",
    "\n",
    "        init = ops.cast(tf.fill([1, label_shape[1]], 0), dtype=\"bool\")\n",
    "        dense_mask = tf.compat.v1.scan(\n",
    "            range_less_than, label_lengths, initializer=init, parallel_iterations=1\n",
    "        )\n",
    "        dense_mask = dense_mask[:, 0, :]\n",
    "\n",
    "        label_array = ops.reshape(\n",
    "            ops.tile(ops.arange(0, label_shape[1]), num_batches_tns), label_shape\n",
    "        )\n",
    "        label_ind = tf.compat.v1.boolean_mask(label_array, dense_mask)\n",
    "\n",
    "        batch_array = ops.transpose(\n",
    "            ops.reshape(\n",
    "                ops.tile(ops.arange(0, label_shape[0]), max_num_labels_tns),\n",
    "                tf.reverse(label_shape, [0]),\n",
    "            )\n",
    "        )\n",
    "        batch_ind = tf.compat.v1.boolean_mask(batch_array, dense_mask)\n",
    "        indices = ops.transpose(\n",
    "            ops.reshape(ops.concatenate([batch_ind, label_ind], axis=0), [2, -1])\n",
    "        )\n",
    "\n",
    "        vals_sparse = tf.compat.v1.gather_nd(labels, indices)\n",
    "\n",
    "        return tf.SparseTensor(\n",
    "            ops.cast(indices, dtype=\"int64\"),\n",
    "            vals_sparse,\n",
    "            ops.cast(label_shape, dtype=\"int64\")\n",
    "        )\n",
    "\n",
    "    @keras.saving.register_keras_serializable(package=\"customs\", name=\"CTCLayer\")\n",
    "    class CTCLayer(layers.Layer):\n",
    "        \"\"\"\n",
    "        Custom Keras layer for calculating CTC loss.\n",
    "\n",
    "        Args:\n",
    "        - trainable (bool): Whether the layer is trainable.\n",
    "        - dtype (str): Data type of the layer.\n",
    "        - name (str): Name of the layer.\n",
    "        \"\"\"\n",
    "        def __init__(self, trainable=True, dtype='float32', name=None, **kwargs):\n",
    "            super().__init__(trainable=trainable, dtype=dtype, name=name, **kwargs)\n",
    "            self.loss_fn = ctc_batch_cost\n",
    "\n",
    "        def call(self, y_true, y_pred):\n",
    "            batch_len = ops.cast(ops.shape(y_true)[0], dtype=\"int64\")\n",
    "            input_length = ops.cast(ops.shape(y_pred)[1], dtype=\"int64\")\n",
    "            label_length = ops.cast(ops.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "            input_length = input_length * ops.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "            label_length = label_length * ops.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "            loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "            self.add_loss(loss)\n",
    "\n",
    "            return y_pred\n",
    "\n",
    "    def build_model(num_conv_layers=2, filter_size=3, activation='tanh'):\n",
    "        \"\"\"\n",
    "        Builds the OCR model consisting of CNN and RNN layers.\n",
    "\n",
    "        Args:\n",
    "        - num_conv_layers (int): Number of convolutional layers.\n",
    "        - filter_size (int): Size of the convolutional filters.\n",
    "        - activation (str): Activation function used in the convolutional layers.\n",
    "\n",
    "        Returns:\n",
    "        - keras.models.Model: Compiled OCR model.\n",
    "        \"\"\"\n",
    "        input_img = layers.Input(\n",
    "            shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
    "        )\n",
    "        labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "        x = input_img\n",
    "        for i in range(num_conv_layers):\n",
    "            x = layers.Conv2D(\n",
    "                64,\n",
    "                (filter_size, filter_size),\n",
    "                activation=activation,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                padding=\"same\",\n",
    "                name=f\"Conv{i+1}\",\n",
    "            )(x)\n",
    "            x = layers.MaxPooling2D((2, 2), name=f\"pool{i+1}\")(x)\n",
    "\n",
    "        downscale_factor = 2 ** num_conv_layers\n",
    "        new_shape = ((img_width // downscale_factor), (img_height // downscale_factor) * 64)    \n",
    "        x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "        x = layers.Dense(\n",
    "            len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\"\n",
    "        )(x)\n",
    "\n",
    "        output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "        model = keras.models.Model(\n",
    "            inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n",
    "        )\n",
    "\n",
    "        opt = keras.optimizers.Adam()\n",
    "        model.compile(optimizer=opt)\n",
    "        return model\n",
    "\n",
    "\n",
    "    # Get the model\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    epochs = 3\n",
    "    early_stopping_patience = 10\n",
    "    # Add early stopping\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    preds = model.predict(test_dataset)\n",
    "\n",
    "    def ctc_decode2(y_pred):\n",
    "        \"\"\"\n",
    "        Decodes the predicted labels using the CTC decoding algorithm.\n",
    "\n",
    "        Args:\n",
    "        - y_pred (tensor): Predicted labels.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: Tuple containing the decoded labels and their log probabilities.\n",
    "        \"\"\"\n",
    "        input_length = np.ones(preds.shape[0]) * preds.shape[1]\n",
    "        input_shape = ops.shape(y_pred)\n",
    "        num_samples, num_steps = input_shape[0], input_shape[1]\n",
    "        y_pred = ops.log(ops.transpose(y_pred, axes=[1, 0, 2]) + keras.backend.epsilon())\n",
    "        input_length = ops.cast(input_length, dtype=\"int32\")\n",
    "\n",
    "        (decoded, log_prob) = tf.nn.ctc_greedy_decoder(\n",
    "            inputs=y_pred, sequence_length=input_length\n",
    "        )\n",
    "\n",
    "        decoded_dense = []\n",
    "        for st in decoded:\n",
    "            st = tf.SparseTensor(st.indices, st.values, (num_samples, num_steps))\n",
    "            decoded_dense.append(tf.sparse.to_dense(sp_input=st, default_value=-1))\n",
    "\n",
    "        dec = (decoded_dense, log_prob)\n",
    "\n",
    "        return dec\n",
    "\n",
    "    def decode_to_utf8(y_pred):\n",
    "        \"\"\"\n",
    "        Decodes the predicted labels to UTF-8 format.\n",
    "\n",
    "        Args:\n",
    "        - y_pred (numpy.ndarray): Predicted labels.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of decoded labels in UTF-8 format.\n",
    "        \"\"\"\n",
    "        y_pred = np.where(y_pred == -1, 1, y_pred)\n",
    "        charst = num_to_char(y_pred)\n",
    "        decoded_text_numpy = np.array(charst)\n",
    "        decoded_text_utf8 = np.char.decode(decoded_text_numpy.astype('bytes'), 'utf-8')\n",
    "\n",
    "        res_words = [''.join(filter(lambda x: x != ' ', row)) for row in decoded_text_utf8]\n",
    "\n",
    "        return res_words\n",
    "\n",
    "    dec = ctc_decode2(preds)[0][0][:, :max_length]\n",
    "    print(dec.shape)\n",
    "    # res = decode_to_utf8(dec)\n",
    "    # print(res)\n",
    "\n",
    "    for batch in test_dataset:\n",
    "        batch_images = batch[\"image\"]\n",
    "        batch_labels = batch[\"label\"]\n",
    "\n",
    "    print(len(batch_images))\n",
    "    print(len(batch_labels))\n",
    "\n",
    "    prediction_model = keras.models.Model(\n",
    "        model.input[0], model.get_layer(name=\"dense2\").output\n",
    "    )\n",
    "    prediction_model.summary()\n",
    "    #  Let's check results on some validation samples\n",
    "    for batch in test_dataset.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        batch_labels = batch[\"label\"]\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        # pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        dec = ctc_decode2(preds)[0][0][:, :max_length]\n",
    "        pred_texts = decode_to_utf8(dec)\n",
    "        # pred_texts = pred_texts.astype(str)\n",
    "\n",
    "        orig_texts = []\n",
    "        for label in batch_labels:\n",
    "            label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "            orig_texts.append(label)\n",
    "\n",
    "        _, ax = plt.subplots(4, 4, figsize=(15, 5))\n",
    "        for i in range(len(pred_texts)):\n",
    "            img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n",
    "            img = img.T\n",
    "            title = f\"Prediction: {pred_texts[i]}\\nReal: {orig_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    def levenshtein(s1, s2):\n",
    "        \"\"\"\n",
    "        Computes the Levenshtein distance between two strings.\n",
    "\n",
    "        Args:\n",
    "        - s1 (str): First string.\n",
    "        - s2 (str): Second string.\n",
    "\n",
    "        Returns:\n",
    "        - int: Levenshtein distance between the strings.\n",
    "        \"\"\"\n",
    "        dp = [[0] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n",
    "\n",
    "        for i in range(len(s1) + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len(s2) + 1):\n",
    "            dp[0][j] = j\n",
    "        \n",
    "        for i in range(1, len(s1) + 1):\n",
    "            for j in range(1, len(s2) + 1):\n",
    "                if s1[i - 1] == s2[j - 1]:\n",
    "                    cost = 0\n",
    "                else:\n",
    "                    cost = 1\n",
    "                dp[i][j] = min(dp[i - 1][j] + 1,\n",
    "                            dp[i][j - 1] + 1,\n",
    "                            dp[i - 1][j - 1] + cost)\n",
    "        return dp[len(s1)][len(s2)]\n",
    "\n",
    "    total_distance = 0\n",
    "    num_samples = 0\n",
    "    for batch in validation_dataset:\n",
    "        batch_images = batch[\"image\"]\n",
    "        batch_labels = batch[\"label\"]\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        dec = ctc_decode2(preds)[0][0][:, :max_length]\n",
    "        pred_texts = decode_to_utf8(dec)\n",
    "        \n",
    "        orig_texts = []\n",
    "        for label in batch_labels:\n",
    "            label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "            orig_texts.append(label)\n",
    "\n",
    "        for i in range(len(pred_texts)):\n",
    "            total_distance += levenshtein(pred_texts[i], orig_texts[i])\n",
    "            num_samples += 1\n",
    "\n",
    "\n",
    "    # Calculate and print the average Levenshtein distance\n",
    "    average_distance = total_distance / num_samples\n",
    "    print(f\"Average Levenshtein Distance: {average_distance}\")\n",
    "    return average_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(results):\n",
    "    \"\"\"\n",
    "    Performs the t-student test on the results of different combinations.\n",
    "\n",
    "    Args:\n",
    "    - results (dict): Dictionary containing combinations as keys and their corresponding results as values.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    best_result = min(results.values())\n",
    "    best_combination = min(results, key=results.get)\n",
    "    print(f\"Best combination: {best_combination}, Best result: {best_result}\")\n",
    "    \n",
    "    for combination, result in results.items():\n",
    "        if combination != best_combination:\n",
    "            statistic, p_value = stats.ttest_rel(results[best_combination], result)\n",
    "            if p_value < 0.05:  # Przyjmujemy poziom istotnoÅ›ci 0.05\n",
    "                print(f\"Combination {combination} is significantly different from the best combination.\")\n",
    "            else:\n",
    "                print(f\"No significant difference found for combination {combination}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_preprocessing():\n",
    "    \"\"\"\n",
    "    Experiment 1: Preprocessing Image Techniques.\n",
    "\n",
    "    This function performs an experiment on preprocessing image techniques, \n",
    "    evaluating the effect of different scaling factors and normalization methods.\n",
    "\n",
    "    Returns:\n",
    "    - best_combination (tuple): Best combination of preprocessing techniques.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    scaling_factors = [0.5, 1.0, 1.5]\n",
    "    normalizations = [\"zscore\", \"minmax\"]\n",
    "\n",
    "    preprocessing_combinations = list(itertools.product(scaling_factors, normalizations))\n",
    "\n",
    "    for combination in preprocessing_combinations:\n",
    "        scaling_factor, normalization = combination\n",
    "        \n",
    "        # Display current combination\n",
    "        print(f\"Preprocessing combination: Scaling factor: {scaling_factor}, Normalization: {normalization}\")\n",
    "        result = model_full(scaling_factor, normalization, 3, 'tanh')\n",
    "        results[combination] = result\n",
    "\n",
    "    print(\"Results:\")\n",
    "    for combination, result in results.items():\n",
    "        print(f\"Combination: {combination}, Average Distance: {result}\")\n",
    "\n",
    "    # Find the best result (minimum Levenshtein distance)\n",
    "    best_result = min(results.values())\n",
    "    best_combination = min(results, key=results.get)\n",
    "    print(f\"Best combination from Experiment 1: {best_combination}, Best result: {best_result}\")\n",
    "    t_test(results)\n",
    "    return best_combination\n",
    "\n",
    "def experiment_hyperparameters(best_combination):\n",
    "    \"\"\"\n",
    "    Experiment 2: Hyperparameter Optimization.\n",
    "\n",
    "    This function performs an experiment on hyperparameter optimization,\n",
    "    evaluating the effect of different filter sizes and activation functions.\n",
    "\n",
    "    Args:\n",
    "    - best_combination (tuple): Best combination of preprocessing techniques from Experiment 1.\n",
    "\n",
    "    Returns:\n",
    "    - best_combination (tuple): Best combination of hyperparameters.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    filter_sizes = [5, 10, 15]\n",
    "    activations = [\"tanh\", \"relu\", \"sigmoid\", \"softmax\"]\n",
    "\n",
    "    hyperparameter_combinations = list(itertools.product(filter_sizes, activations))\n",
    "\n",
    "    for combination in hyperparameter_combinations:\n",
    "        filter_size, activation = combination\n",
    "        \n",
    "        # Display current combination\n",
    "        print(f\"Hyperparameter combination: Number of Conv Layers: Filter Size: {filter_size}, Activation: {activation}\")\n",
    "        result = model_full(best_combination[0], best_combination[1], filter_size, activation)\n",
    "        results[combination] = result\n",
    "\n",
    "    print(\"Results:\")\n",
    "    for combination, result in results.items():\n",
    "        print(f\"Combination: {combination}, Average Distance: {result}\")\n",
    "\n",
    "    # Find the best result (minimum Levenshtein distance)\n",
    "    best_result = min(results.values())\n",
    "    best_combination = min(results, key=results.get)\n",
    "    print(f\"Best combination from Experiment 2: {best_combination}, Best result: {best_result}\")\n",
    "    t_test(results)\n",
    "    return best_combination\n",
    "\n",
    "# Run experiments\n",
    "print(\"Experiment 1: Preprocessing Image Techniques\")\n",
    "best_combination1 = experiment_preprocessing()\n",
    "\n",
    "print(\"\\nExperiment 2: Hyperparameter Optimization\")\n",
    "best_combination2 = experiment_hyperparameters(best_combination1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
